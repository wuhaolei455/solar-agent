"""
Demo 10: AI è‡ªåª’ä½“è¿è¥åŠ©æ‰‹ (Content Creator Assistant)

å¤š Agent åä½œæ¶æ„ï¼šPlanner + Pipeline + Reflection + Human-in-the-loop
- Planner: ä»»åŠ¡æ‹†è§£ï¼ˆçƒ­ç‚¹è°ƒç ” â†’ å†…å®¹åˆ›ä½œ â†’ å®¡æ ¸ â†’ ä¼˜åŒ–ï¼‰
- Trend Researcher: çƒ­ç‚¹è¯é¢˜è°ƒç ”ï¼ˆTool Use: æœç´¢ APIï¼‰
- Content Creator: é•¿æ–‡åˆ›ä½œï¼ˆæ”¯æŒå¤šç§é£æ ¼ï¼‰
- Fact Checker: äº‹å®æ ¸æŸ¥ï¼ˆå¹¶è¡Œï¼‰
- SEO Optimizer: SEO ä¼˜åŒ–ï¼ˆå¹¶è¡Œï¼‰
- Editor: ä¸»ç¼–å®¡æ ¸ï¼ˆReflectionï¼‰
- Platform Adapter: å¤šå¹³å°æ ¼å¼é€‚é…ï¼ˆç»“æ„åŒ–è¾“å‡ºï¼‰

å›¾ç»“æ„ï¼š
  START â†’ planner â†’ trend_researcher â†’ content_creator
                                           â†“
                      â”Œâ”€ fact_checker â”€â”€â”€â”€â”€â”€â”¤
                      â””â”€ seo_optimizer â”€â”€â”€â”€â”€â”˜
                                â†“
                            editor (review)
                                â†“
                   â”Œâ”€ revise â†’ content_creator (å¸¦åé¦ˆ)
                   â””â”€ approve â†’ platform_adapter â†’ END
"""

import os
import json
import operator
from typing import TypedDict, Annotated, Literal
from shared import setup

import gradio as gr
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, START, END

setup()

# ======================== å…¨å±€æ¨¡å‹ ========================

llm = init_chat_model("openai:gpt-5.2", temperature=0)
creative_llm = init_chat_model("openai:gpt-5.2", temperature=0.8)


# ======================== State å®šä¹‰ ========================

class ContentCreationState(TypedDict):
    topic: str                          # ç”¨æˆ·è¾“å…¥çš„ä¸»é¢˜
    style: str                          # å†…å®¹é£æ ¼ï¼ˆä¸“ä¸š/è½»æ¾/å¹½é»˜ï¼‰
    plan: list[str]                     # Planner æ‹†è§£çš„ä»»åŠ¡æ­¥éª¤
    trend_research: str                 # çƒ­ç‚¹è°ƒç ”ç»“æœ
    draft: str                          # å†…å®¹åˆç¨¿
    fact_check_result: str              # äº‹å®æ ¸æŸ¥ç»“æœ
    seo_suggestions: str                # SEO ä¼˜åŒ–å»ºè®®
    editor_review: str                  # ä¸»ç¼–å®¡æ ¸æ„è§
    editor_score: int                   # ä¸»ç¼–è¯„åˆ† (1-10)
    revision_count: int                 # ä¿®æ”¹æ¬¡æ•°
    final_content: dict                 # æœ€ç»ˆå†…å®¹ï¼ˆå¤šå¹³å°æ ¼å¼ï¼‰
    progress: Annotated[list[str], operator.add]  # è¿›åº¦æ—¥å¿—


# ======================== æœç´¢å·¥å…·ï¼ˆæ¨¡æ‹Ÿï¼‰========================

@tool
def search_hot_topics(keyword: str) -> str:
    """æœç´¢å½“å‰çƒ­ç‚¹è¯é¢˜å’Œè¶‹åŠ¿ã€‚è¾“å…¥å…³é”®è¯ï¼Œè¿”å›çƒ­ç‚¹ä¿¡æ¯ã€‚"""
    # æ¨¡æ‹Ÿæœç´¢ç»“æœ â€” å®é™…é¡¹ç›®ä¸­å¯æ¥å…¥å¾®åšçƒ­æœã€ç™¾åº¦æŒ‡æ•°ã€Google Trends ç­‰
    return (
        f"ã€çƒ­ç‚¹è°ƒç ” - {keyword}ã€‘\n\n"
        f"**çƒ­é—¨è¯é¢˜ï¼š**\n"
        f"1. #{keyword}æŠ€æœ¯çªç ´# - çƒ­åº¦æŒ‡æ•° 850,000\n"
        f"   æœ€æ–°æ¶ˆæ¯ï¼šæŸçŸ¥åä¼ä¸šå®£å¸ƒåœ¨{keyword}é¢†åŸŸå–å¾—é‡å¤§è¿›å±•\n\n"
        f"2. #{keyword}åº”ç”¨æ¡ˆä¾‹# - çƒ­åº¦æŒ‡æ•° 620,000\n"
        f"   ç”¨æˆ·å…³æ³¨ç‚¹ï¼šå®é™…åº”ç”¨æ•ˆæœã€æˆæœ¬ã€å¯è¡Œæ€§\n\n"
        f"3. #{keyword}vsä¼ ç»Ÿæ–¹æ¡ˆ# - çƒ­åº¦æŒ‡æ•° 430,000\n"
        f"   è®¨è®ºç„¦ç‚¹ï¼šä¼˜åŠ¿å¯¹æ¯”ã€é€‚ç”¨åœºæ™¯ã€æŠ•èµ„å›æŠ¥\n\n"
        f"**ç”¨æˆ·ç—›ç‚¹ï¼š**\n"
        f"- ä¸æ¸…æ¥š{keyword}çš„å®é™…åº”ç”¨ä»·å€¼\n"
        f"- æ‹…å¿ƒæŠ€æœ¯ä¸æˆç†Ÿã€è½åœ°å›°éš¾\n"
        f"- å¸Œæœ›çœ‹åˆ°çœŸå®æ¡ˆä¾‹å’Œæ•°æ®æ”¯æ’‘\n\n"
        f"**å†…å®¹å»ºè®®è§’åº¦ï¼š**\n"
        f"- é€šä¿—è®²è§£{keyword}çš„åŸç†å’Œä»·å€¼\n"
        f"- åˆ†äº«çœŸå®æ¡ˆä¾‹å’Œæ•°æ®\n"
        f"- å¯¹æ¯”åˆ†æä¼˜åŠ£åŠ¿\n"
        f"- é¢„æµ‹æœªæ¥å‘å±•è¶‹åŠ¿"
    )


@tool
def search_competitor_content(keyword: str) -> str:
    """æœç´¢ç«å“å†…å®¹å’Œçˆ†æ¬¾æ–‡ç« ã€‚è¾“å…¥å…³é”®è¯ï¼Œè¿”å›ä¼˜ç§€å†…å®¹å‚è€ƒã€‚"""
    return (
        f"ã€ç«å“å†…å®¹åˆ†æ - {keyword}ã€‘\n\n"
        f"**çˆ†æ¬¾æ–‡ç« æ ‡é¢˜ï¼š**\n"
        f"1. ã€Š{keyword}ï¼šè¢«ä½ä¼°çš„æŠ€æœ¯é©å‘½ã€‹- 10ä¸‡+ é˜…è¯»\n"
        f"   æˆåŠŸè¦ç´ ï¼šæ ‡é¢˜å¸ç› + æ•°æ®å¯è§†åŒ– + æ¡ˆä¾‹ä¸°å¯Œ\n\n"
        f"2. ã€Šä¸€æ–‡è¯»æ‡‚{keyword}çš„å‰ä¸–ä»Šç”Ÿã€‹- 8ä¸‡+ é˜…è¯»\n"
        f"   æˆåŠŸè¦ç´ ï¼šç»“æ„æ¸…æ™° + é€šä¿—æ˜“æ‡‚ + é…å›¾ç²¾ç¾\n\n"
        f"3. ã€Š{keyword}å®æˆ˜æŒ‡å—ï¼šä»0åˆ°1ã€‹- 6ä¸‡+ é˜…è¯»\n"
        f"   æˆåŠŸè¦ç´ ï¼šå¹²è´§æ»¡æ»¡ + å¯æ“ä½œæ€§å¼º + ç”¨æˆ·ç—›ç‚¹æ˜ç¡®\n\n"
        f"**å†…å®¹å…±æ€§ï¼š**\n"
        f"- æ ‡é¢˜åŒ…å«æ•°å­—ã€ç–‘é—®æˆ–å¯¹æ¯”\n"
        f"- å¼€å¤´ç›´å‡»ç”¨æˆ·ç—›ç‚¹\n"
        f"- æ­£æ–‡æœ‰æ•°æ®æ”¯æ’‘å’Œæ¡ˆä¾‹\n"
        f"- ç»“å°¾æœ‰è¡ŒåŠ¨æŒ‡å¼•"
    )


# ======================== Agent èŠ‚ç‚¹ ========================

def planner_node(state: ContentCreationState) -> dict:
    """Planner Agent: ä»»åŠ¡è§„åˆ’å’Œæ‹†è§£"""
    topic = state["topic"]
    style = state["style"]

    plan = [
        "ğŸ“Š çƒ­ç‚¹è°ƒç ”ï¼šæœç´¢çƒ­é—¨è¯é¢˜å’Œç”¨æˆ·ç—›ç‚¹",
        f"âœï¸ å†…å®¹åˆ›ä½œï¼šæ’°å†™{style}é£æ ¼çš„é•¿æ–‡",
        "ğŸ” äº‹å®æ ¸æŸ¥ï¼šéªŒè¯æ•°æ®å’Œè§‚ç‚¹å‡†ç¡®æ€§",
        "ğŸ¯ SEO ä¼˜åŒ–ï¼šä¼˜åŒ–æ ‡é¢˜å’Œå…³é”®è¯å¸ƒå±€",
        "ğŸ‘” ä¸»ç¼–å®¡æ ¸ï¼šè´¨é‡è¯„ä¼°å’Œæ”¹è¿›å»ºè®®",
        "ğŸ“± å¹³å°é€‚é…ï¼šç”Ÿæˆå¤šå¹³å°æ ¼å¼"
    ]

    return {
        "plan": plan,
        "progress": [f"ğŸ“‹ **Planner** å·²åˆ¶å®šå†…å®¹åˆ›ä½œè®¡åˆ’ï¼ˆå…± {len(plan)} æ­¥ï¼‰"]
    }


def trend_researcher_node(state: ContentCreationState) -> dict:
    """Trend Researcher Agent: çƒ­ç‚¹è°ƒç ”"""
    topic = state["topic"]

    # è°ƒç”¨æœç´¢å·¥å…·
    hot_topics = search_hot_topics.invoke({"keyword": topic})
    competitor_content = search_competitor_content.invoke({"keyword": topic})

    research_result = f"{hot_topics}\n\n---\n\n{competitor_content}"

    return {
        "trend_research": research_result,
        "progress": ["ğŸ” **Trend Researcher** å®Œæˆçƒ­ç‚¹è°ƒç ”"]
    }


def content_creator_node(state: ContentCreationState) -> dict:
    """Content Creator Agent: å†…å®¹åˆ›ä½œ"""
    topic = state["topic"]
    style = state["style"]
    research = state["trend_research"]
    editor_review = state.get("editor_review", "")

    revision_hint = ""
    if editor_review:
        revision_hint = f"\n\nâš ï¸ ä¸»ç¼–å®¡æ ¸æ„è§ï¼ˆè¯·æ ¹æ®åé¦ˆä¿®æ”¹ï¼‰ï¼š\n{editor_review}"

    style_guide = {
        "ä¸“ä¸š": "ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼Œæ•°æ®é©±åŠ¨ï¼Œé€»è¾‘ä¸¥å¯†ï¼Œé€‚åˆè¡Œä¸šä»ä¸šè€…é˜…è¯»",
        "è½»æ¾": "è¯­è¨€æ´»æ³¼ï¼Œé€šä¿—æ˜“æ‡‚ï¼Œå¤šç”¨æ¯”å–»å’Œæ¡ˆä¾‹ï¼Œé€‚åˆå¤§ä¼—è¯»è€…",
        "å¹½é»˜": "è½»æ¾è¯™è°ï¼Œé€‚å½“è°ƒä¾ƒï¼Œæ®µå­å’Œæ¢—é€‚åº¦ï¼Œé€‚åˆå¹´è½»ç”¨æˆ·"
    }

    response = creative_llm.invoke([
        SystemMessage(content=f"""ä½ æ˜¯ä¸€ä½ä¼˜ç§€çš„è‡ªåª’ä½“å†…å®¹åˆ›ä½œè€…ã€‚è¯·æ ¹æ®è°ƒç ”ç»“æœæ’°å†™ä¸€ç¯‡é«˜è´¨é‡æ–‡ç« ã€‚

**é£æ ¼è¦æ±‚ï¼š** {style_guide.get(style, "ä¸“ä¸šä¸¥è°¨")}

**æ–‡ç« ç»“æ„ï¼š**
1. **å¸ç›æ ‡é¢˜**ï¼ˆåŒ…å«æ•°å­—ã€ç–‘é—®æˆ–å¯¹æ¯”ï¼‰
2. **å¼€å¤´**ï¼ˆç›´å‡»ç—›ç‚¹ï¼Œå¼•å‘å…±é¸£ï¼‰
3. **æ­£æ–‡**ï¼ˆ3-5 ä¸ªå°èŠ‚ï¼Œæ¯èŠ‚æœ‰å°æ ‡é¢˜ï¼‰
   - é€šä¿—è®²è§£æ ¸å¿ƒæ¦‚å¿µ
   - çœŸå®æ¡ˆä¾‹å’Œæ•°æ®æ”¯æ’‘
   - ä¼˜åŠ£åŠ¿å¯¹æ¯”åˆ†æ
   - æœªæ¥è¶‹åŠ¿é¢„æµ‹
4. **ç»“å°¾**ï¼ˆæ€»ç»“ + è¡ŒåŠ¨æŒ‡å¼•ï¼‰

**å†™ä½œè¦æ±‚ï¼š**
- æ€»å­—æ•° 1500-2500 å­—
- ä½¿ç”¨ Markdown æ ¼å¼
- æ¯ä¸ªè§‚ç‚¹éƒ½æœ‰æ•°æ®æˆ–æ¡ˆä¾‹æ”¯æ’‘
- å¤šç”¨å°æ ‡é¢˜ã€åˆ—è¡¨ã€åŠ ç²—ç­‰æ’ç‰ˆå…ƒç´ {revision_hint}"""),
        HumanMessage(content=f"ä¸»é¢˜ï¼š{topic}\n\nè°ƒç ”ç»“æœï¼š\n{research}")
    ])

    revision_count = state.get("revision_count", 0)
    label = "ä¿®æ”¹ç¨¿" if revision_count > 0 else "åˆç¨¿"

    return {
        "draft": response.content,
        "revision_count": revision_count + 1,
        "progress": [f"âœï¸ **Content Creator** å®Œæˆ{label}ï¼ˆç¬¬ {revision_count + 1} ç‰ˆï¼‰"]
    }


def fact_checker_node(state: ContentCreationState) -> dict:
    """Fact Checker Agent: äº‹å®æ ¸æŸ¥ï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰"""
    draft = state["draft"]

    response = llm.invoke([
        SystemMessage(content="""ä½ æ˜¯ä¸“ä¸šçš„äº‹å®æ ¸æŸ¥å‘˜ã€‚è¯·æ£€æŸ¥æ–‡ç« ä¸­çš„æ•°æ®ã€è§‚ç‚¹æ˜¯å¦å‡†ç¡®å¯ä¿¡ã€‚

æ£€æŸ¥ç»´åº¦ï¼š
1. æ•°æ®æ¥æºæ˜¯å¦å¯é 
2. ç»Ÿè®¡æ•°å­—æ˜¯å¦åˆç†
3. å› æœå…³ç³»æ˜¯å¦æˆç«‹
4. æ˜¯å¦æœ‰å¸¸è¯†æ€§é”™è¯¯

è¯·è¾“å‡º JSON æ ¼å¼ï¼š
{
  "issues": [
    {"location": "ç¬¬Xæ®µ", "problem": "é—®é¢˜æè¿°", "severity": "é«˜/ä¸­/ä½"}
  ],
  "overall": "æ•´ä½“è¯„ä»·",
  "passed": true/false
}

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""),
        HumanMessage(content=draft)
    ])

    try:
        content = response.content.strip()
        if content.startswith("```"):
            content = content.split("\n", 1)[1].rsplit("```", 1)[0].strip()
        result = json.loads(content)
        issues = result.get("issues", [])
        passed = result.get("passed", True)

        if passed:
            fact_check_text = "âœ… äº‹å®æ ¸æŸ¥é€šè¿‡ï¼Œæœªå‘ç°æ˜æ˜¾é—®é¢˜"
        else:
            issues_text = "\n".join([f"- {issue['location']}: {issue['problem']}" for issue in issues[:3]])
            fact_check_text = f"âš ï¸ å‘ç° {len(issues)} å¤„é—®é¢˜ï¼š\n{issues_text}"
    except (json.JSONDecodeError, KeyError):
        fact_check_text = "âœ… äº‹å®æ ¸æŸ¥é€šè¿‡"

    return {
        "fact_check_result": fact_check_text,
        "progress": ["ğŸ” **Fact Checker** å®Œæˆäº‹å®æ ¸æŸ¥"]
    }


def seo_optimizer_node(state: ContentCreationState) -> dict:
    """SEO Optimizer Agent: SEO ä¼˜åŒ–å»ºè®®ï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰"""
    draft = state["draft"]
    topic = state["topic"]

    response = llm.invoke([
        SystemMessage(content="""ä½ æ˜¯ SEO ä¼˜åŒ–ä¸“å®¶ã€‚è¯·åˆ†ææ–‡ç« çš„ SEO è¡¨ç°å¹¶æä¾›ä¼˜åŒ–å»ºè®®ã€‚

åˆ†æç»´åº¦ï¼š
1. æ ‡é¢˜æ˜¯å¦åŒ…å«å…³é”®è¯
2. å…³é”®è¯å¯†åº¦æ˜¯å¦åˆç†
3. å°æ ‡é¢˜ç»“æ„æ˜¯å¦æ¸…æ™°
4. æ˜¯å¦æœ‰å†…å¤–é“¾æœºä¼š
5. meta æè¿°å»ºè®®

è¯·ç»™å‡ºå…·ä½“çš„ä¼˜åŒ–å»ºè®®ï¼ˆ3-5 æ¡ï¼‰ã€‚"""),
        HumanMessage(content=f"ä¸»é¢˜å…³é”®è¯ï¼š{topic}\n\næ–‡ç« å†…å®¹ï¼š\n{draft}")
    ])

    return {
        "seo_suggestions": response.content,
        "progress": ["ğŸ¯ **SEO Optimizer** å®Œæˆ SEO åˆ†æ"]
    }


def editor_node(state: ContentCreationState) -> dict:
    """Editor Agent: ä¸»ç¼–å®¡æ ¸ï¼ˆReflectionï¼‰"""
    draft = state["draft"]
    fact_check = state["fact_check_result"]
    seo = state["seo_suggestions"]

    response = llm.invoke([
        SystemMessage(content="""ä½ æ˜¯èµ„æ·±å†…å®¹ä¸»ç¼–ã€‚è¯·ç»¼åˆè¯„ä¼°æ–‡ç« è´¨é‡å¹¶ç»™å‡ºå®¡æ ¸æ„è§ã€‚

è¯„ä¼°ç»´åº¦ï¼š
1. **å¸å¼•åŠ›** (1-10)ï¼šæ ‡é¢˜å’Œå¼€å¤´æ˜¯å¦å¸ç›
2. **å†…å®¹è´¨é‡** (1-10)ï¼šè®ºè¯æ˜¯å¦å……åˆ†ã€æ¡ˆä¾‹æ˜¯å¦ä¸°å¯Œ
3. **å¯è¯»æ€§** (1-10)ï¼šæ’ç‰ˆæ˜¯å¦æ¸…æ™°ã€è¯­è¨€æ˜¯å¦æµç•…
4. **äº‹å®å‡†ç¡®æ€§** (1-10)ï¼šåŸºäºäº‹å®æ ¸æŸ¥ç»“æœ
5. **SEO å‹å¥½åº¦** (1-10)ï¼šåŸºäº SEO åˆ†æç»“æœ

è¯·è¾“å‡º JSON æ ¼å¼ï¼š
{
  "scores": {"å¸å¼•åŠ›": 8, "å†…å®¹è´¨é‡": 7, ...},
  "overall_score": 8,
  "passed": true,
  "feedback": "å…·ä½“çš„å®¡æ ¸æ„è§å’Œä¿®æ”¹å»ºè®®..."
}

overall_score >= 8 ä¸”æ— ç¡¬ä¼¤æ—¶ passed ä¸º trueï¼Œå¦åˆ™ä¸º falseã€‚
åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""),
        HumanMessage(content=f"æ–‡ç« ï¼š\n{draft}\n\näº‹å®æ ¸æŸ¥ï¼š{fact_check}\n\nSEO åˆ†æï¼š{seo}")
    ])

    try:
        content = response.content.strip()
        if content.startswith("```"):
            content = content.split("\n", 1)[1].rsplit("```", 1)[0].strip()
        result = json.loads(content)
        score = result.get("overall_score", 8)
        feedback = result.get("feedback", "")
        passed = result.get("passed", score >= 8)
        scores_detail = result.get("scores", {})
    except (json.JSONDecodeError, KeyError):
        score = 8
        feedback = "å®¡æ ¸é€šè¿‡ï¼Œå†…å®¹è´¨é‡åˆæ ¼ã€‚"
        passed = True
        scores_detail = {}

    scores_str = " | ".join(f"{k}:{v}" for k, v in scores_detail.items()) if scores_detail else ""
    status = "âœ… é€šè¿‡" if passed else "ğŸ”„ éœ€ä¿®æ”¹"

    return {
        "editor_review": feedback,
        "editor_score": score,
        "progress": [
            f"ğŸ‘” **Editor** å®¡æ ¸å®Œæˆ â€” {status}ï¼ˆç»¼åˆè¯„åˆ†ï¼š{score}/10ï¼‰\n"
            f"   {scores_str}\n"
            f"   æ„è§ï¼š{feedback[:80]}..."
        ]
    }


def platform_adapter_node(state: ContentCreationState) -> dict:
    """Platform Adapter Agent: å¤šå¹³å°æ ¼å¼é€‚é…"""
    draft = state["draft"]

    response = llm.invoke([
        SystemMessage(content="""ä½ æ˜¯å¤šå¹³å°å†…å®¹é€‚é…ä¸“å®¶ã€‚è¯·å°†æ–‡ç« æ”¹ç¼–ä¸ºä¸åŒå¹³å°æ ¼å¼ã€‚

è¯·è¾“å‡º JSON æ ¼å¼ï¼ˆåŒ…å« 3 ä¸ªå¹³å°ç‰ˆæœ¬ï¼‰ï¼š
{
  "wechat": {
    "title": "é€‚åˆå…¬ä¼—å·çš„æ ‡é¢˜",
    "summary": "æ‘˜è¦ï¼ˆ100å­—å†…ï¼‰",
    "content": "å®Œæ•´å†…å®¹ï¼ˆä¿ç•™åŸæ–‡æ ¸å¿ƒï¼Œä¼˜åŒ–æ’ç‰ˆï¼‰"
  },
  "weibo": {
    "title": "å¾®åšæ ‡é¢˜ï¼ˆ50å­—å†…ï¼‰",
    "content": "å¾®åšæ­£æ–‡ï¼ˆ280å­—å†…ï¼Œæç‚¼æ ¸å¿ƒè§‚ç‚¹ + è¯é¢˜æ ‡ç­¾ï¼‰"
  },
  "xiaohongshu": {
    "title": "å°çº¢ä¹¦æ ‡é¢˜ï¼ˆå¸ç›ã€å£è¯­åŒ–ï¼‰",
    "content": "å°çº¢ä¹¦æ­£æ–‡ï¼ˆ800å­—å†…ï¼Œå¤šç”¨ emojiã€åˆ†æ®µæ˜ç¡®ï¼‰"
  }
}

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""),
        HumanMessage(content=draft)
    ])

    try:
        content = response.content.strip()
        if content.startswith("```"):
            content = content.split("\n", 1)[1].rsplit("```", 1)[0].strip()
        final_content = json.loads(content)
    except (json.JSONDecodeError, KeyError):
        final_content = {
            "wechat": {"title": "å†…å®¹æ ‡é¢˜", "content": draft},
            "weibo": {"title": "å†…å®¹æ ‡é¢˜", "content": draft[:280]},
            "xiaohongshu": {"title": "å†…å®¹æ ‡é¢˜", "content": draft[:800]},
        }

    return {
        "final_content": final_content,
        "progress": ["ğŸ“± **Platform Adapter** å®Œæˆå¤šå¹³å°æ ¼å¼é€‚é…"]
    }


# ======================== æ¡ä»¶è·¯ç”± ========================

def should_revise(state: ContentCreationState) -> Literal["content_creator", "platform_adapter"]:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦ä¿®æ”¹"""
    score = state.get("editor_score", 10)
    revision_count = state.get("revision_count", 0)

    if score < 8 and revision_count < 2:
        return "content_creator"
    return "platform_adapter"


# ======================== æ„å»º Graph ========================

def build_content_creation_graph():
    graph = StateGraph(ContentCreationState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("planner", planner_node)
    graph.add_node("trend_researcher", trend_researcher_node)
    graph.add_node("content_creator", content_creator_node)
    graph.add_node("fact_checker", fact_checker_node)
    graph.add_node("seo_optimizer", seo_optimizer_node)
    graph.add_node("editor", editor_node)
    graph.add_node("platform_adapter", platform_adapter_node)

    # æ·»åŠ è¾¹
    graph.add_edge(START, "planner")
    graph.add_edge("planner", "trend_researcher")
    graph.add_edge("trend_researcher", "content_creator")

    # å¹¶è¡Œæ‰§è¡Œäº‹å®æ ¸æŸ¥å’Œ SEO ä¼˜åŒ–
    graph.add_edge("content_creator", "fact_checker")
    graph.add_edge("content_creator", "seo_optimizer")

    # ä¸¤ä¸ªå¹¶è¡Œä»»åŠ¡å®Œæˆåï¼Œè¿›å…¥ä¸»ç¼–å®¡æ ¸
    graph.add_edge("fact_checker", "editor")
    graph.add_edge("seo_optimizer", "editor")

    # ä¸»ç¼–å®¡æ ¸åï¼Œæ¡ä»¶è·¯ç”±
    graph.add_conditional_edges("editor", should_revise, {
        "content_creator": "content_creator",
        "platform_adapter": "platform_adapter",
    })

    graph.add_edge("platform_adapter", END)

    return graph.compile()


# ======================== Gradio å‰ç«¯ ========================

content_creation_app = build_content_creation_graph()


def create_content(topic: str, style: str):
    """æµå¼è¿è¡Œå†…å®¹åˆ›ä½œç³»ç»Ÿ"""
    if not topic.strip():
        yield "âš ï¸ è¯·è¾“å…¥å†…å®¹ä¸»é¢˜", "", "", ""
        return

    progress_text = f"## ğŸš€ å¼€å§‹åˆ›ä½œï¼š{topic}ï¼ˆé£æ ¼ï¼š{style}ï¼‰\n\n"
    draft_text = ""
    wechat_text = ""
    other_platforms_text = ""

    yield progress_text + "â³ æ­£åœ¨å¯åŠ¨å†…å®¹åˆ›ä½œæµç¨‹...", draft_text, wechat_text, other_platforms_text

    # æµå¼æ‰§è¡Œ
    for event in content_creation_app.stream(
        {"topic": topic, "style": style, "revision_count": 0},
        stream_mode="updates",
    ):
        for node_name, node_output in event.items():
            # æ›´æ–°è¿›åº¦
            if "progress" in node_output:
                for log in node_output["progress"]:
                    progress_text += f"\n{log}\n"

            # æ›´æ–°è‰ç¨¿
            if "draft" in node_output:
                draft_text = node_output["draft"]

            # æ›´æ–°æœ€ç»ˆå†…å®¹
            if "final_content" in node_output:
                final = node_output["final_content"]
                wechat = final.get("wechat", {})
                weibo = final.get("weibo", {})
                xiaohongshu = final.get("xiaohongshu", {})

                wechat_text = f"# {wechat.get('title', '')}\n\n{wechat.get('content', '')}"

                other_platforms_text = f"## ğŸ“± å¾®åšç‰ˆæœ¬\n\n**æ ‡é¢˜ï¼š** {weibo.get('title', '')}\n\n{weibo.get('content', '')}\n\n"
                other_platforms_text += f"---\n\n## ğŸ“± å°çº¢ä¹¦ç‰ˆæœ¬\n\n**æ ‡é¢˜ï¼š** {xiaohongshu.get('title', '')}\n\n{xiaohongshu.get('content', '')}"

            yield progress_text, draft_text, wechat_text, other_platforms_text

    yield progress_text + "\n---\nğŸ‰ **å†…å®¹åˆ›ä½œå®Œæˆï¼**", draft_text, wechat_text, other_platforms_text


with gr.Blocks(theme=gr.themes.Soft(), title="AI è‡ªåª’ä½“è¿è¥åŠ©æ‰‹") as chat_ui:
    gr.Markdown("# ğŸ“ AI è‡ªåª’ä½“è¿è¥åŠ©æ‰‹\nå¤š Agent åä½œï¼šPlanner â†’ Researcher â†’ Creator â†’ [Fact Check + SEO] â†’ Editor â†’ Platform Adapter")

    with gr.Row():
        topic_input = gr.Textbox(
            label="å†…å®¹ä¸»é¢˜",
            placeholder="ä¾‹å¦‚ï¼šäººå·¥æ™ºèƒ½åœ¨æ•™è‚²è¡Œä¸šçš„åº”ç”¨",
            scale=3
        )
        style_input = gr.Dropdown(
            label="å†…å®¹é£æ ¼",
            choices=["ä¸“ä¸š", "è½»æ¾", "å¹½é»˜"],
            value="è½»æ¾",
            scale=1
        )
        create_btn = gr.Button("ğŸš€ å¼€å§‹åˆ›ä½œ", variant="primary", scale=1)

    with gr.Row():
        with gr.Column(scale=1):
            progress_output = gr.Markdown(label="ğŸ“‹ åˆ›ä½œè¿›åº¦", value="*ç­‰å¾…è¾“å…¥ä¸»é¢˜...*")

        with gr.Column(scale=2):
            with gr.Tabs():
                with gr.Tab("ğŸ“„ åŸç¨¿"):
                    draft_output = gr.Markdown(value="*å†…å®¹åˆç¨¿å°†åœ¨è¿™é‡Œæ˜¾ç¤º...*")
                with gr.Tab("ğŸ“± å…¬ä¼—å·ç‰ˆ"):
                    wechat_output = gr.Markdown(value="*å…¬ä¼—å·ç‰ˆæœ¬å°†åœ¨è¿™é‡Œæ˜¾ç¤º...*")
                with gr.Tab("ğŸ“± å…¶ä»–å¹³å°"):
                    other_output = gr.Markdown(value="*å¾®åšå’Œå°çº¢ä¹¦ç‰ˆæœ¬å°†åœ¨è¿™é‡Œæ˜¾ç¤º...*")

    create_btn.click(
        fn=create_content,
        inputs=[topic_input, style_input],
        outputs=[progress_output, draft_output, wechat_output, other_output],
    )

    gr.Examples(
        examples=[
            ["äººå·¥æ™ºèƒ½åœ¨æ•™è‚²è¡Œä¸šçš„åº”ç”¨", "è½»æ¾"],
            ["2025å¹´æ–°èƒ½æºæ±½è½¦å¸‚åœºè¶‹åŠ¿", "ä¸“ä¸š"],
            ["ç¨‹åºå‘˜å¦‚ä½•é«˜æ•ˆå­¦ä¹ æ–°æŠ€æœ¯", "å¹½é»˜"],
        ],
        inputs=[topic_input, style_input],
    )


if __name__ == "__main__":
    os.environ.setdefault("no_proxy", "localhost,127.0.0.1")
    chat_ui.launch(server_name="127.0.0.1", server_port=7892, share=False)

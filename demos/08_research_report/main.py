"""
Demo 08: æ·±åº¦ç ”æŠ¥ç³»ç»Ÿ (Deep Research Report)

å¤š Agent åä½œæ¶æ„ï¼šSupervisor + Pipeline + Reflection
- Plannerï¼šå°†ç”¨æˆ·ä¸»é¢˜æ‹†è§£ä¸ºå­ç ”ç©¶é—®é¢˜
- Researcherï¼šå¯¹æ¯ä¸ªå­é—®é¢˜æœé›†èµ„æ–™ï¼ˆReAct Agent + å·¥å…·ï¼‰
- Analystï¼šäº¤å‰åˆ†æï¼Œæç‚¼å…³é”®æ´å¯Ÿ
- Writerï¼šæ’°å†™ç»“æ„åŒ–ç ”æŠ¥
- Reviewerï¼šè´¨é‡å®¡æ ¸ï¼Œä¸åˆæ ¼é€€å›ä¿®æ”¹ï¼ˆReflectionï¼‰

å›¾ç»“æ„ï¼š
  START â†’ planner â†’ researcher â†’ analyst â†’ writer â†’ reviewer
                                             â†‘          â”‚
                                             â””â”€â”€ revise â”€â”˜ (max 2 rounds)
                                                        â”‚
                                                        â””â”€â”€ END (final_report)
"""

import os
import json
import operator
from typing import TypedDict, Annotated, Literal
from shared import setup

import gradio as gr
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import create_react_agent

setup()

# ======================== å…¨å±€æ¨¡å‹ ========================

llm = init_chat_model("openai:gpt-5.2", temperature=0)
creative_llm = init_chat_model("openai:gpt-5.2", temperature=0.7)


# ======================== State å®šä¹‰ ========================

class ResearchState(TypedDict):
    topic: str                    # ç”¨æˆ·è¾“å…¥çš„ç ”ç©¶ä¸»é¢˜
    sub_questions: list[str]      # Planner æ‹†è§£çš„å­é—®é¢˜
    research_data: Annotated[list[str], operator.add]  # Researcher æœé›†çš„èµ„æ–™ï¼ˆå¯è¿½åŠ ï¼‰
    analysis: str                 # Analyst åˆ†æç»“è®º
    draft: str                    # Writer æ’°å†™çš„åˆç¨¿
    review: str                   # Reviewer çš„å®¡æ ¸æ„è§
    review_score: int             # Reviewer çš„è¯„åˆ† (1-10)
    final_report: str             # æœ€ç»ˆè¾“å‡ºçš„ç ”æŠ¥
    revision_count: int           # å·²ä¿®æ”¹æ¬¡æ•°
    progress: Annotated[list[str], operator.add]  # å„é˜¶æ®µè¿›åº¦æ—¥å¿—


# ======================== æœç´¢å·¥å…·ï¼ˆæ¨¡æ‹Ÿï¼‰========================

@tool
def web_search(query: str) -> str:
    """æœç´¢äº’è”ç½‘è·å–ç›¸å…³ä¿¡æ¯ã€‚è¾“å…¥æœç´¢å…³é”®è¯ï¼Œè¿”å›æœç´¢ç»“æœæ‘˜è¦ã€‚"""
    # æ¨¡æ‹Ÿæœç´¢ç»“æœ â€” å®é™…é¡¹ç›®ä¸­å¯æ¥å…¥ Tavily / SerpAPI ç­‰
    return (
        f"ã€æœç´¢ç»“æœ - {query}ã€‘\n"
        f"1. æ ¹æ®æœ€æ–°ç ”ç©¶æ•°æ®æ˜¾ç¤ºï¼Œ{query}é¢†åŸŸåœ¨2024-2025å¹´å‘ˆç°æ˜¾è‘—å¢é•¿è¶‹åŠ¿ï¼Œ"
        f"å¹´å‡å¢é•¿ç‡çº¦15-20%ã€‚\n"
        f"2. è¡Œä¸šä¸“å®¶æŒ‡å‡ºï¼Œ{query}çš„æ ¸å¿ƒé©±åŠ¨å› ç´ åŒ…æ‹¬æŠ€æœ¯åˆ›æ–°ã€æ”¿ç­–æ”¯æŒå’Œå¸‚åœºéœ€æ±‚ä¸‰ä¸ªç»´åº¦ã€‚\n"
        f"3. ä¸»è¦æŒ‘æˆ˜åŒ…æ‹¬ï¼šäººæ‰çŸ­ç¼ºã€æ ‡å‡†åŒ–ä¸è¶³ã€æŠ•èµ„å›æŠ¥å‘¨æœŸé•¿ç­‰ã€‚\n"
        f"4. é¢„è®¡åˆ°2026å¹´ï¼Œè¯¥é¢†åŸŸå¸‚åœºè§„æ¨¡å°†è¾¾åˆ°å½“å‰çš„2-3å€ã€‚\n"
        f"5. é¢†å…ˆä¼ä¸šå·²å¼€å§‹å¸ƒå±€ä¸‹ä¸€ä»£æŠ€æœ¯è·¯çº¿ï¼Œç«äº‰æ ¼å±€æ­£åœ¨é‡å¡‘ã€‚"
    )


@tool
def search_academic_papers(query: str) -> str:
    """æœç´¢å­¦æœ¯è®ºæ–‡å’Œç ”ç©¶æŠ¥å‘Šã€‚è¾“å…¥ç ”ç©¶ä¸»é¢˜ï¼Œè¿”å›ç›¸å…³å­¦æœ¯æˆæœã€‚"""
    return (
        f"ã€å­¦æœ¯è®ºæ–‡ - {query}ã€‘\n"
        f"1. ã€Š{query}çš„å‰æ²¿è¿›å±•ä¸æœªæ¥å±•æœ›ã€‹(2025) - ç»¼è¿°äº†è¯¥é¢†åŸŸæœ€æ–°ç†è®ºæ¡†æ¶å’Œå®è¯ç ”ç©¶ã€‚\n"
        f"2. ã€ŠåŸºäºæ•°æ®é©±åŠ¨çš„{query}åˆ†ææ–¹æ³•ã€‹(2024) - æå‡ºäº†æ–°çš„é‡åŒ–åˆ†ææ¨¡å‹ã€‚\n"
        f"3. ã€Š{query}çš„å›½é™…æ¯”è¾ƒç ”ç©¶ã€‹(2025) - å¯¹æ¯”äº†ä¸­ç¾æ¬§ä¸‰å¤§å¸‚åœºçš„å‘å±•è·¯å¾„ã€‚"
    )


@tool
def search_market_data(query: str) -> str:
    """æœç´¢å¸‚åœºæ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯ã€‚è¾“å…¥æŸ¥è¯¢å†…å®¹ï¼Œè¿”å›ç›¸å…³å¸‚åœºæ•°æ®ã€‚"""
    return (
        f"ã€å¸‚åœºæ•°æ® - {query}ã€‘\n"
        f"- 2024å¹´å¸‚åœºè§„æ¨¡ï¼šçº¦ 850 äº¿ç¾å…ƒ\n"
        f"- 2025å¹´é¢„ä¼°å¸‚åœºè§„æ¨¡ï¼šçº¦ 1020 äº¿ç¾å…ƒï¼ˆåŒæ¯”å¢é•¿ 20%ï¼‰\n"
        f"- ä¸»è¦å‚ä¸è€…å¸‚åœºä»½é¢ï¼šå¤´éƒ¨ä¼ä¸šå æ¯”çº¦ 45%ï¼Œä¸­å°ä¼ä¸šå æ¯” 55%\n"
        f"- æŠ•èèµ„æƒ…å†µï¼š2024å¹´å…¨å¹´èèµ„äº‹ä»¶è¶… 200 èµ·ï¼Œæ€»é¢çº¦ 150 äº¿ç¾å…ƒ"
    )


# ======================== å„ Agent èŠ‚ç‚¹ ========================

def planner_node(state: ResearchState) -> dict:
    """Planner Agentï¼šæ‹†è§£ç ”ç©¶ä¸»é¢˜ä¸ºå­é—®é¢˜"""
    topic = state["topic"]

    response = llm.invoke([
        SystemMessage(content="""ä½ æ˜¯ä¸€ä½èµ„æ·±ç ”ç©¶ç­–åˆ’ä¸“å®¶ã€‚
ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·ç»™å‡ºçš„ç ”ç©¶ä¸»é¢˜æ‹†è§£ä¸º 3-5 ä¸ªå…·ä½“çš„å­ç ”ç©¶é—®é¢˜ã€‚

è¦æ±‚ï¼š
1. å­é—®é¢˜åº”è¦†ç›–è¯¥ä¸»é¢˜çš„æ ¸å¿ƒç»´åº¦ï¼ˆç°çŠ¶ã€è¶‹åŠ¿ã€æŒ‘æˆ˜ã€æœºé‡ç­‰ï¼‰
2. å­é—®é¢˜ä¹‹é—´ä¸é‡å ï¼Œä¸”åˆåœ¨ä¸€èµ·èƒ½å…¨é¢è¦†ç›–ä¸»é¢˜
3. æ¯ä¸ªå­é—®é¢˜åº”å…·ä½“ã€å¯æœç´¢

è¯·ä»¥ JSON æ•°ç»„æ ¼å¼è¿”å›ï¼Œä¾‹å¦‚ï¼š
["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3"]

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""),
        HumanMessage(content=f"ç ”ç©¶ä¸»é¢˜ï¼š{topic}")
    ])

    try:
        # å°è¯•è§£æ JSON
        content = response.content.strip()
        # å¤„ç†å¯èƒ½çš„ markdown ä»£ç å—åŒ…è£¹
        if content.startswith("```"):
            content = content.split("\n", 1)[1].rsplit("```", 1)[0].strip()
        sub_questions = json.loads(content)
    except (json.JSONDecodeError, IndexError):
        sub_questions = [
            f"{topic}çš„å‘å±•ç°çŠ¶å’Œå¸‚åœºè§„æ¨¡",
            f"{topic}çš„æ ¸å¿ƒæŠ€æœ¯å’Œåˆ›æ–°è¶‹åŠ¿",
            f"{topic}é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜å’Œé£é™©",
            f"{topic}çš„æœªæ¥å‘å±•å‰æ™¯å’ŒæŠ•èµ„æœºä¼š",
        ]

    return {
        "sub_questions": sub_questions,
        "progress": [f"ğŸ“‹ **Planner** å·²å°†ä¸»é¢˜æ‹†è§£ä¸º {len(sub_questions)} ä¸ªå­é—®é¢˜ï¼š\n" +
                     "\n".join(f"  {i+1}. {q}" for i, q in enumerate(sub_questions))]
    }


def researcher_node(state: ResearchState) -> dict:
    """Researcher Agentï¼ˆReActï¼‰ï¼šå¯¹å­é—®é¢˜æœé›†èµ„æ–™"""
    sub_questions = state["sub_questions"]

    # ä¸º Researcher åˆ›å»º ReAct Agent
    researcher = create_react_agent(
        model=llm,
        tools=[web_search, search_academic_papers, search_market_data],
        prompt=(
            "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç ”ç©¶å‘˜ã€‚é’ˆå¯¹ç»™å®šçš„ç ”ç©¶é—®é¢˜ï¼Œä½¿ç”¨æœç´¢å·¥å…·æœé›†å…¨é¢çš„èµ„æ–™ã€‚"
            "è¯·ç»¼åˆå¤šä¸ªæ¥æºçš„ä¿¡æ¯ï¼Œæ•´ç†å‡ºç»“æ„åŒ–çš„ç ”ç©¶ç´ æã€‚"
            "æ¯ä¸ªé—®é¢˜è‡³å°‘ä½¿ç”¨ 2 ä¸ªä¸åŒçš„æœç´¢å·¥å…·è·å–ä¿¡æ¯ã€‚"
        ),
    )

    all_data = []
    progress_log = []

    for i, question in enumerate(sub_questions):
        result = researcher.invoke({
            "messages": [HumanMessage(content=f"è¯·é’ˆå¯¹ä»¥ä¸‹é—®é¢˜è¿›è¡Œæ·±å…¥ç ”ç©¶ï¼š{question}")]
        })

        # æå–æœ€ç»ˆå›ç­”
        final_msg = result["messages"][-1].content
        all_data.append(f"### å­é—®é¢˜ {i+1}ï¼š{question}\n\n{final_msg}")
        progress_log.append(
            f"ğŸ” **Researcher** å®Œæˆå­é—®é¢˜ {i+1}/{len(sub_questions)} çš„èµ„æ–™æœé›†"
        )

    return {
        "research_data": all_data,
        "progress": progress_log
    }


def analyst_node(state: ResearchState) -> dict:
    """Analyst Agentï¼šäº¤å‰åˆ†æï¼Œæç‚¼å…³é”®æ´å¯Ÿ"""
    topic = state["topic"]
    research_data = "\n\n---\n\n".join(state["research_data"])

    response = llm.invoke([
        SystemMessage(content="""ä½ æ˜¯ä¸€ä½èµ„æ·±è¡Œä¸šåˆ†æå¸ˆã€‚
æ ¹æ®æä¾›çš„ç ”ç©¶ç´ æï¼Œè¿›è¡Œäº¤å‰åˆ†æå¹¶æç‚¼å…³é”®æ´å¯Ÿã€‚

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œåˆ†æï¼š
1. **æ ¸å¿ƒå‘ç°**ï¼šæœ€é‡è¦çš„ 3-5 ä¸ªå‘ç°
2. **è¶‹åŠ¿åˆ¤æ–­**ï¼šæœªæ¥ 1-3 å¹´çš„å‘å±•è¶‹åŠ¿
3. **é£é™©è¯„ä¼°**ï¼šä¸»è¦é£é™©å› ç´ å’Œæ¦‚ç‡
4. **æ•°æ®æ”¯æ’‘**ï¼šå…³é”®æ•°æ®ç‚¹æ€»ç»“
5. **ç‹¬ç‰¹æ´å¯Ÿ**ï¼šåŸºäºäº¤å‰åˆ†æå¾—å‡ºçš„ç‹¬ç‰¹è§è§£

è¯·è¾“å‡ºç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Šã€‚"""),
        HumanMessage(content=f"ç ”ç©¶ä¸»é¢˜ï¼š{topic}\n\nç ”ç©¶ç´ æï¼š\n{research_data}")
    ])

    return {
        "analysis": response.content,
        "progress": ["ğŸ“Š **Analyst** å·²å®Œæˆæ·±åº¦åˆ†æï¼Œæç‚¼å‡ºå…³é”®æ´å¯Ÿ"]
    }


def writer_node(state: ResearchState) -> dict:
    """Writer Agentï¼šæ’°å†™ç»“æ„åŒ–ç ”æŠ¥"""
    topic = state["topic"]
    analysis = state["analysis"]
    review = state.get("review", "")

    revision_hint = ""
    if review:
        revision_hint = f"\n\nâš ï¸ ä¸Šä¸€è½®å®¡æ ¸æ„è§ï¼ˆè¯·æ ¹æ®ä»¥ä¸‹åé¦ˆä¿®æ”¹ï¼‰ï¼š\n{review}"

    response = creative_llm.invoke([
        SystemMessage(content=f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç ”æŠ¥æ’°å†™äººã€‚
è¯·æ ¹æ®åˆ†æå¸ˆæä¾›çš„åˆ†æç»“æœï¼Œæ’°å†™ä¸€ä»½å®Œæ•´çš„æ·±åº¦ç ”ç©¶æŠ¥å‘Šã€‚

æŠ¥å‘Šç»“æ„è¦æ±‚ï¼š
1. **æ‘˜è¦**ï¼ˆ200å­—ä»¥å†…ï¼‰
2. **ç ”ç©¶èƒŒæ™¯ä¸ç›®çš„**
3. **æ ¸å¿ƒå‘ç°**ï¼ˆåˆ†ç‚¹è®ºè¿°ï¼Œæ¯ç‚¹æœ‰æ•°æ®æ”¯æ’‘ï¼‰
4. **è¶‹åŠ¿åˆ†æ**
5. **é£é™©ä¸æŒ‘æˆ˜**
6. **æŠ•èµ„/è¡ŒåŠ¨å»ºè®®**
7. **ç»“è®º**

å†™ä½œè¦æ±‚ï¼š
- è¯­è¨€ä¸“ä¸šä¸¥è°¨ï¼Œä½†ä¸æ™¦æ¶©
- æ¯ä¸ªè®ºç‚¹éƒ½è¦æœ‰æ•°æ®æˆ–äº‹å®æ”¯æ’‘
- ä½¿ç”¨ Markdown æ ¼å¼
- æ€»å­—æ•° 1500-2500 å­—{revision_hint}"""),
        HumanMessage(content=f"ç ”ç©¶ä¸»é¢˜ï¼š{topic}\n\nåˆ†æç»“æœï¼š\n{analysis}")
    ])

    revision_count = state.get("revision_count", 0)
    label = "ä¿®æ”¹ç¨¿" if revision_count > 0 else "åˆç¨¿"

    return {
        "draft": response.content,
        "revision_count": revision_count + 1,
        "progress": [f"âœï¸ **Writer** å·²å®Œæˆç ”æŠ¥{label}ï¼ˆç¬¬ {revision_count + 1} ç‰ˆï¼‰"]
    }


def reviewer_node(state: ResearchState) -> dict:
    """Reviewer Agentï¼ˆReflectionï¼‰ï¼šå®¡æ ¸ç ”æŠ¥è´¨é‡"""
    draft = state["draft"]
    topic = state["topic"]

    response = llm.invoke([
        SystemMessage(content="""ä½ æ˜¯ä¸€ä½ä¸¥æ ¼çš„ç ”æŠ¥å®¡æ ¸ä¸“å®¶ã€‚
è¯·ä»ä»¥ä¸‹ç»´åº¦å¯¹ç ”æŠ¥è¿›è¡Œè¯„åˆ†å’Œå®¡æ ¸ï¼š

1. **é€»è¾‘æ€§** (1-10)ï¼šè®ºè¯æ˜¯å¦ä¸¥å¯†ã€ç»“æ„æ˜¯å¦æ¸…æ™°
2. **æ•°æ®æ”¯æ’‘** (1-10)ï¼šå…³é”®è®ºç‚¹æ˜¯å¦æœ‰æ•°æ®ä½è¯
3. **å¯è¯»æ€§** (1-10)ï¼šè¯­è¨€æ˜¯å¦æµç•…ã€æ’ç‰ˆæ˜¯å¦åˆç†
4. **å®Œæ•´æ€§** (1-10)ï¼šæ˜¯å¦è¦†ç›–äº†ä¸»é¢˜çš„æ ¸å¿ƒç»´åº¦

è¯·è¾“å‡º JSON æ ¼å¼ï¼š
{
  "scores": {"é€»è¾‘æ€§": 8, "æ•°æ®æ”¯æ’‘": 7, "å¯è¯»æ€§": 9, "å®Œæ•´æ€§": 8},
  "overall_score": 8,
  "passed": true,
  "feedback": "å…·ä½“çš„å®¡æ ¸æ„è§å’Œä¿®æ”¹å»ºè®®..."
}

overall_score >= 7 ä¸”æ— ç¡¬ä¼¤æ—¶ passed ä¸º trueï¼Œå¦åˆ™ä¸º falseã€‚
åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""),
        HumanMessage(content=f"ç ”ç©¶ä¸»é¢˜ï¼š{topic}\n\nç ”æŠ¥å†…å®¹ï¼š\n{draft}")
    ])

    try:
        content = response.content.strip()
        if content.startswith("```"):
            content = content.split("\n", 1)[1].rsplit("```", 1)[0].strip()
        result = json.loads(content)
        score = result.get("overall_score", 7)
        feedback = result.get("feedback", "")
        passed = result.get("passed", score >= 7)
        scores_detail = result.get("scores", {})
    except (json.JSONDecodeError, KeyError):
        score = 7
        feedback = "å®¡æ ¸é€šè¿‡ï¼ŒæŠ¥å‘Šè´¨é‡åˆæ ¼ã€‚"
        passed = True
        scores_detail = {}

    scores_str = " | ".join(f"{k}:{v}" for k, v in scores_detail.items()) if scores_detail else ""
    status = "âœ… é€šè¿‡" if passed else "ğŸ”„ éœ€ä¿®æ”¹"

    return {
        "review": feedback,
        "review_score": score,
        "progress": [
            f"ğŸ” **Reviewer** å®¡æ ¸å®Œæˆ â€” {status}ï¼ˆç»¼åˆè¯„åˆ†ï¼š{score}/10ï¼‰\n"
            f"   {scores_str}\n"
            f"   æ„è§ï¼š{feedback[:100]}..."
        ]
    }


def publish_node(state: ResearchState) -> dict:
    """è¾“å‡ºæœ€ç»ˆç ”æŠ¥"""
    return {
        "final_report": state["draft"],
        "progress": ["ğŸ“„ **æœ€ç»ˆç ”æŠ¥å·²ç”Ÿæˆ** âœ…"]
    }


# ======================== æ¡ä»¶è·¯ç”± ========================

def should_revise(state: ResearchState) -> Literal["writer", "publish"]:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦é€€å›ä¿®æ”¹"""
    score = state.get("review_score", 10)
    revision_count = state.get("revision_count", 0)

    if score < 7 and revision_count < 3:
        return "writer"
    return "publish"


# ======================== æ„å»º Graph ========================

def build_research_graph():
    graph = StateGraph(ResearchState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("planner", planner_node)
    graph.add_node("researcher", researcher_node)
    graph.add_node("analyst", analyst_node)
    graph.add_node("writer", writer_node)
    graph.add_node("reviewer", reviewer_node)
    graph.add_node("publish", publish_node)

    # æ·»åŠ è¾¹
    graph.add_edge(START, "planner")
    graph.add_edge("planner", "researcher")
    graph.add_edge("researcher", "analyst")
    graph.add_edge("analyst", "writer")
    graph.add_edge("writer", "reviewer")

    # Reflection æ¡ä»¶è¾¹
    graph.add_conditional_edges("reviewer", should_revise, {
        "writer": "writer",
        "publish": "publish",
    })
    graph.add_edge("publish", END)

    return graph.compile()


# ======================== Gradio å‰ç«¯ ========================

research_app = build_research_graph()


def run_research(topic: str):
    """æµå¼è¿è¡Œç ”æŠ¥ç³»ç»Ÿï¼Œé€æ­¥è¿”å›è¿›åº¦"""
    if not topic.strip():
        yield "âš ï¸ è¯·è¾“å…¥ç ”ç©¶ä¸»é¢˜", ""
        return

    progress_text = f"## ğŸš€ å¼€å§‹ç ”ç©¶ï¼š{topic}\n\n"
    report_text = ""

    yield progress_text + "â³ æ­£åœ¨å¯åŠ¨ç ”ç©¶æµç¨‹...", report_text

    # ä½¿ç”¨ stream æ¨¡å¼é€æ­¥è·å–å„èŠ‚ç‚¹çš„è¾“å‡º
    for event in research_app.stream(
        {"topic": topic, "revision_count": 0},
        stream_mode="updates",
    ):
        for node_name, node_output in event.items():
            # æ›´æ–°è¿›åº¦
            if "progress" in node_output:
                for log in node_output["progress"]:
                    progress_text += f"\n{log}\n"

            # æ›´æ–°æŠ¥å‘Š
            if "final_report" in node_output:
                report_text = node_output["final_report"]
            elif "draft" in node_output:
                report_text = f"*ï¼ˆè‰ç¨¿ - å®¡æ ¸ä¸­...ï¼‰*\n\n{node_output['draft']}"

            yield progress_text, report_text

    # æœ€ç»ˆè¾“å‡º
    if not report_text or report_text.startswith("*ï¼ˆè‰ç¨¿"):
        report_text = "âš ï¸ ç ”æŠ¥ç”Ÿæˆæœªå®Œæˆï¼Œè¯·é‡è¯•ã€‚"

    yield progress_text + "\n---\nğŸ‰ **å…¨éƒ¨æµç¨‹å·²å®Œæˆï¼**", report_text


with gr.Blocks(theme=gr.themes.Soft(), title="æ·±åº¦ç ”æŠ¥ç³»ç»Ÿ") as chat_ui:
    gr.Markdown("# ğŸ“Š æ·±åº¦ç ”æŠ¥ç³»ç»Ÿ\nå¤š Agent åä½œï¼šPlanner â†’ Researcher â†’ Analyst â†’ Writer â†’ Reviewer")

    with gr.Row():
        topic_input = gr.Textbox(
            label="ç ”ç©¶ä¸»é¢˜",
            placeholder="ä¾‹å¦‚ï¼šäººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¡Œä¸šçš„åº”ç”¨å‰æ™¯",
            scale=4
        )
        run_btn = gr.Button("ğŸš€ ç”Ÿæˆç ”æŠ¥", variant="primary", scale=1)

    with gr.Row():
        with gr.Column(scale=1):
            progress_output = gr.Markdown(label="ğŸ“‹ ç ”ç©¶è¿›åº¦", value="*ç­‰å¾…è¾“å…¥ä¸»é¢˜...*")
        with gr.Column(scale=2):
            report_output = gr.Markdown(label="ğŸ“„ ç ”æŠ¥å†…å®¹", value="*ç ”æŠ¥å°†åœ¨è¿™é‡Œæ˜¾ç¤º...*")

    run_btn.click(
        fn=run_research,
        inputs=[topic_input],
        outputs=[progress_output, report_output],
    )

    gr.Examples(
        examples=[
            "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¡Œä¸šçš„åº”ç”¨å‰æ™¯",
            "2025å¹´å…¨çƒæ–°èƒ½æºæ±½è½¦å¸‚åœºåˆ†æ",
            "å¤§è¯­è¨€æ¨¡å‹æŠ€æœ¯å‘å±•è¶‹åŠ¿ä¸å•†ä¸šåŒ–è·¯å¾„",
        ],
        inputs=topic_input,
    )


if __name__ == "__main__":
    os.environ.setdefault("no_proxy", "localhost,127.0.0.1")
    chat_ui.launch(server_name="127.0.0.1", server_port=7890, share=False)

import os
import time
from shared import setup

import gradio as gr
import whisper
import edge_tts
from langchain.chat_models import init_chat_model
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

setup()

# åŠ è½½ Whisper è¯­éŸ³è¯†åˆ«æ¨¡å‹
asr_model = whisper.load_model("turbo")

# å­˜å‚¨ä¸åŒç”¨æˆ·çš„è®°å¿†
store = {}

def get_session_history(session_id: str):
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]


english_tutor_prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a friendly English tutor.

        Help the learner improve step by step.
        Keep responses short, clear, and conversational.

        When correcting:
        - First show the corrected sentence.
        - Then give a very brief reason (1â€“2 short sentences).
        - Use simple, everyday English.
        - Encourage the learner to try again.

        Do not give long explanations or grammar lectures.
    """),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{user_message}"),
])

model = init_chat_model(
    "openai:gpt-5.2",
    temperature=0
)
output_parser = StrOutputParser()

chain = english_tutor_prompt | model | output_parser
chain_with_history = RunnableWithMessageHistory(
    chain,
    get_session_history,
    input_messages_key="user_message",
    history_messages_key="chat_history",
)


def speech_to_text(audio_path: str) -> str:
    """æŠŠç”¨æˆ·è¯­éŸ³è½¬æˆæ–‡æœ¬ï¼ˆWhisper ASRï¼‰"""
    transcribed = asr_model.transcribe(audio_path)
    return transcribed["text"]


def text_to_speech(text: str) -> str:
    """è¾“å…¥æ–‡æœ¬ â†’ è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆEdge TTSï¼‰"""
    print(f"[TTS] Processing: {text}")
    audio_path = f"./output_{int(time.time())}.mp3"
    communicate = edge_tts.Communicate(text, "en-GB-SoniaNeural")
    with open(audio_path, "wb") as file:
        for chunk in communicate.stream_sync():
            if chunk["type"] == "audio":
                file.write(chunk["data"])
    return audio_path


def stream_ai_response(user_message: str, session_id: str):
    """æµå¼è°ƒç”¨å¤§æ¨¡å‹ï¼Œé€ chunk ç”Ÿæˆå›å¤"""
    partial_answer = ""
    for chunk in chain_with_history.stream(
        {"user_message": user_message},
        config={"configurable": {"session_id": session_id}}
    ):
        if chunk:
            partial_answer += chunk
            yield partial_answer


def process_voice_and_stream(audio_path: str, history: list):
    """
    è¯­éŸ³äº¤äº’ä¸»æµç¨‹ï¼š
    1. è¯­éŸ³è¯†åˆ« â†’ æ–‡æœ¬
    2. æµå¼è°ƒç”¨ LLM â†’ æ–‡å­—å›å¤
    3. æ–‡å­—è½¬è¯­éŸ³ â†’ éŸ³é¢‘å›å¤
    """
    user_text = speech_to_text(audio_path)
    if not user_text:
        yield history, None
        return

    history.append({"role": "user", "content": user_text})
    history.append({"role": "assistant", "content": ""})
    yield history, None

    session_id = "user_001"

    full_response = ""
    for partial in stream_ai_response(user_text, session_id):
        full_response = partial
        history[-1]["content"] = full_response
        yield history, None

    audio_reply = text_to_speech(full_response)
    yield history, audio_reply


with gr.Blocks(theme=gr.themes.Soft()) as chat_ui:
    gr.Markdown("# ğŸ™ï¸ æµå¼å¤šæ¨¡æ€è‹±è¯­åŠ©æ‰‹")

    with gr.Row():
        with gr.Column(scale=1):
            audio_input = gr.Audio(
                sources=["microphone"],
                type="filepath",
                label="è¯·å¼€å£è¯´è‹±è¯­ (Speak English)"
            )
            audio_output = gr.Audio(label="AI è¯­éŸ³å›å¤", autoplay=True)

        with gr.Column(scale=2):
            chatbot = gr.Chatbot(label="å¯¹è¯è®°å½•")
            clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯")

    # å½“å½•éŸ³ç»“æŸæ—¶è§¦å‘
    audio_input.stop_recording(
        fn=process_voice_and_stream,
        inputs=[audio_input, chatbot],
        outputs=[chatbot, audio_output]
    )

    clear_btn.click(lambda: [], None, chatbot)


if __name__ == "__main__":
    os.environ.setdefault("no_proxy", "localhost,127.0.0.1")
    chat_ui.launch(server_name="127.0.0.1", server_port=7870, share=False)
